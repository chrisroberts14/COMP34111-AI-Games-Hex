[CREATE MODEL]
; Used for hexhex.model.hexconvolution.Conv and creating RandomModel
board_size = 11

; Parameters we pass to hexhex.model.hexconvolution.Conv
layers = 18
intermediate_channels = 64
reach = 1

; If false, we use hexconvolution.NoSwitchWrapperModel around the above model
switch_model = True

; If true use hexconvolution.RotationWrapperModel around the above model
rotation_model = True

model_name = azagent

[CREATE DATA]
; Values used to initialise RepeatedSelfTrainer
num_train_samples = 2000
num_val_samples = 200

; Batch size of the DataLoader for train and val sets, inside train.py
batch_size = 128

noise = none
noise_parameters = 3,0.5,1
temperature = 0.67
temperature_decay = 1
gamma = 0

[TRAIN]
; Number of complete passes over training data to update model parameters
epochs = 64

batch_size = 64
optimizer = adam
learning_rate = 0.000005
momentum = 0.9
weight_decay = 0.03
print_loss_frequency = 1000

[ELO]
number_of_games = 16
batch_size = 16
num_opened_moves = 1
temperature = 0.
temperature_decay = 0.7
plot_board = false
max_num_opponents = 3

[VS REFERENCE MODELS]
batch_size = 128
num_games = 256

[REPEATED SELF TRAINING]
; Start index of the repeated_self_training.RepeatedSelfTrainer.repeated_self_training loop
start_index = 0

; How many times to run the RST loop, which for each loop:
; Creates training and validation samples
; Run train.train with these samples
; Measure wins against reference model
num_iterations = 1000

num_data_models = 10
load_initial_data = False

; Save data in the "data" directory, after all RST loops have finished
save_data = True

[BAYESIAN OPTIMIZATION]
continue_from_save = False

; Time in seconds to run the repeated self training loop
loop_time = 10

; The total number of function evaluations to perform (how many times the optimizer will call objective function)
loop_count = 20

; Number of iterations where the optimizer randomly samples from the search space before using the Gaussian Process model
random_count = 5

; Number of times the optimizer is restarted to improve convergence
optimizer_restarts = 5

; Accounts for observation noise in the function evaluations (If your objective function has noise (e.g., stochastic outcomes), setting this parameter helps the Gaussian Process model handle it. If the function is deterministic, set it to 0)
noise = 10000

[CREATE PUZZLE]
board_size = 11
num_samples = 4096
batch_size = 256

[EVALUATE MODELS]
model1 = temp0.3/3_2l_5c_0009
model2 = 3_2l_5c_0016
num_opened_moves = 1
number_of_games = 64
batch_size = 64
temperature = 0.7
temperature_decay = 0.7
plot_board = false

[INTERACTIVE]
model = 3_2l_5c_0019
mode = nomcts
temperature = 0
temperature_decay = 1
first_move_ai = true
gui_radius = 50
dark_mode = false
c_puct = 1.25
num_mcts_simulations = 800

[LOGGING]
file = default.log
# a = append, w = write
file_mode = a
console_level = INFO
file_level = DEBUG
